import logging
import time
import sys
import os
from pathlib import Path
from tqdm import tqdm

# Setup path and imports
SRC_ROOT = Path(__file__).parent / "src"
sys.path.insert(0, str(SRC_ROOT))

# External library imports
from langchain_core.documents import Document

# Internal imports
from src.models.multilingual_embedder import MultilingualEmbedder
from src.models.llm_models import OLLAMA_LLM
from src.vectorstores.faiss_vectorstore import Fais_VS
from src.strategies.chat_strategy import ChattingStrategy
from src.strategies.question_strategy import QuestionStrategy
from src.strategies.summarization_strategy import SummarizationStrategy, Summarization_Rag_Strategy
from src.core.task_processor import TaskProcessor
from src.processors.json_processor import JSONPreprocessor
from config.settings import (
    DEFAULT_EMBEDDING_MODEL, DEFAULT_BATCH_SIZE, OLLAMA_MODELS, 
    LOG_LEVEL, LLM_CACHE_DIR
)


def setup_logging():
    """Configure logging for the pipeline."""
    os.makedirs("logs", exist_ok=True)
    
    logging.basicConfig(
        level=getattr(logging, LOG_LEVEL),
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('logs/document_processing.log'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)


def load_and_process_documents(logger,files_paths):
    """Load and process  documents into chunks."""
    logger.info("üìÅ Loading documents...")
    paths = [files_paths]
    docs = JSONPreprocessor()

    with tqdm(total=len(paths), desc="üîÑ Processing  files", unit="file") as pbar:
        data = docs.process_documents_from_files(paths)
        pbar.update(len(paths))

    logger.info(f"‚úÖ Loaded {len(data)} documents")

    logger.info("üìÑ Creating individual documents...")
    individual_documents = [
        Document(page_content=pdf.page_content, metadata={"pdf_id": i})
        for i, pdf in enumerate(tqdm(data, desc="üî® Creating documents", unit="doc"))
        if pdf.page_content
    ]
    logger.info(f"‚úÖ Created {len(individual_documents)} individual documents")

    logger.info("‚úÇÔ∏è Chunking documents...")
    chunked_docs = docs.chunk_documents(individual_documents)
    logger.info(f"‚úÖ Document chunking completed - {len(chunked_docs)} chunks created")

    return chunked_docs , individual_documents


def initialize_models(logger, pipeline_start_time):
    """Initialize embedder and LLM models."""
    logger.info("üß† Initializing multilingual embedder model...")
    with tqdm(total=1, desc="‚ö° Loading embedder", unit="model") as pbar:
        multilingual_embedder = MultilingualEmbedder(
            model_name=DEFAULT_EMBEDDING_MODEL, 
            batch_size=DEFAULT_BATCH_SIZE
        )
        pbar.update(1)

    current_elapsed = time.time() - pipeline_start_time
    logger.info(f"‚úÖ Embedder model loaded - Total elapsed: {current_elapsed:.2f}s")
    print(f"‚è±Ô∏è Time Taken to process embedder: {current_elapsed:.2f}s")

    logger.info("ü§ñ Loading OLLAMA LLM model...")
    with tqdm(total=1, desc="üî• Loading LLM", unit="model") as pbar:
        llm = OLLAMA_LLM(OLLAMA_MODELS["qwen3"], str(LLM_CACHE_DIR)).load_model()
        pbar.update(1)

    current_elapsed = time.time() - pipeline_start_time
    logger.info(f"‚úÖ LLM model loaded - Total elapsed: {current_elapsed:.2f}s")
    print(f"‚è±Ô∏è Time Taken to process LLM: {current_elapsed:.2f}s")

    return multilingual_embedder, llm


def create_vector_store(logger, chunked_docs, multilingual_embedder):
    """Create and populate vector store with document embeddings."""
    logger.info("üóÑÔ∏è Creating vector store...")
    vector_store = Fais_VS()
    vector_store.set_embedder_model(multilingual_embedder)

    with tqdm(total=len(chunked_docs), desc="üî¢ Creating embeddings", unit="chunk") as pbar:
        vector_store.create_vector_store(chunked_docs)
        pbar.update(len(chunked_docs))

    logger.info(f"‚úÖ Vector store created with {len(chunked_docs)} embeddings")
    return vector_store


def initialize_strategies(logger, llm, vector_store, multilingual_embedder, pipeline_start_time):
    """Initialize all processing strategies."""
    logger.info("‚öôÔ∏è Initializing processing strategies...")
    strategies_progress = tqdm(total=5, desc="üîß Initializing strategies", unit="strategy")

    logger.info("üí¨ Initializing Chatting Strategy...")
    chatting_strategy = ChattingStrategy(llm, vector_store, multilingual_embedder)
    strategies_progress.update(1)

    logger.info("üìù Initializing Summarization Strategy...")
    summarization_strategy = SummarizationStrategy(llm)
    strategies_progress.update(1)

    logger.info("‚ùì Initializing Question Strategy...")
    question_strategy = QuestionStrategy(llm)
    strategies_progress.update(1)

    logger.info("üîç Initializing RAG Summary Strategy...")
    rag_summary = Summarization_Rag_Strategy(llm, vector_store)
    strategies_progress.update(1)

    logger.info("üéØ Initializing Task Processor...")
    processor = TaskProcessor()
    strategies_progress.update(1)
    strategies_progress.close()

    current_elapsed = time.time() - pipeline_start_time
    logger.info(f"‚úÖ All strategies initialized - Total elapsed: {current_elapsed:.2f}s")
    print(f"‚è±Ô∏è Time Taken to process strategies: {current_elapsed:.2f}s")

    return chatting_strategy, summarization_strategy , question_strategy , rag_summary , processor




def main():
    """Main pipeline execution function."""
    pipeline_start_time = time.time()
    logger = setup_logging()
    logger.info("üöÄ Starting document processing pipeline...")

    try:
        # Load and process documents
        chunked_docs , individual_documents = load_and_process_documents(logger,'/Users/maryamsaad/Documents/app/data/PMS Market Research_extracted_text.json')

        # Initialize models
        multilingual_embedder, llm = initialize_models(logger, pipeline_start_time)

        # Create vector store
        vector_store = create_vector_store(logger, chunked_docs, multilingual_embedder)

        # Initialize strategies
        chatting_strategy, summarization_strategy , question_strategy , rag_summary , processor = initialize_strategies(
            logger, llm, vector_store, multilingual_embedder, pipeline_start_time
        )
        # processor.strategy =chatting_strategy
        # processor.execute_task("\nWhat tranlation platforms are in the document\n")
        processor.strategy =summarization_strategy
        processor.execute_task(individual_documents[0].page_content,length="medium", verbose=False, overview_level='low_level')
        processor.strategy=question_strategy
        processor.execute_task(individual_documents[0],20,'hard')
        processor.strategy=rag_summary
        processor.execute_task("Translation Platforms")

 

        # Final timing
        final_elapsed_time = time.time() - pipeline_start_time
        logger.info(f"‚úÖ Pipeline completed - Total time: {final_elapsed_time:.2f}s")
        print(f"üéâ Pipeline completed successfully in {final_elapsed_time:.2f}s!")

    

    except Exception as e:
        logger.error(f"‚ùå Pipeline failed: {str(e)}")
        print(f"‚ùå Error: {str(e)}")
        raise


if __name__ == "__main__":
    result = main()